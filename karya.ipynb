{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xy-3F27_HB0f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Different Functions for Different Descriptions\n",
        "def comp_description(comp_name,response):\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        #print(soup)\n",
        "        # Check if the 'About' section exists on the page\n",
        "        abt_section = soup.find('span', {'class': 'description ng-star-inserted'})\n",
        "\n",
        "        if abt_section:\n",
        "            # Check if text content is available\n",
        "            descp = abt_section.text.strip() if abt_section.text else \"No description Found\"\n",
        "            return descp\n",
        "        else:\n",
        "            return f\"No Description found for {comp_name}\"\n",
        "    else:\n",
        "        return f\"Failed to get info. Error: {response.status_code}\""
      ],
      "metadata": {
        "id": "QWTyj2LBHWAh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fsector(comp_name,response):\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        #print(soup)\n",
        "        # Check if sector exists on the page\n",
        "        sector = soup.find('span', {'class': 'component--field-formatter field-type-enum ng-star-inserted'})\n",
        "\n",
        "        if sector:\n",
        "            # Check if text content is available\n",
        "            t_sec = sector.text.strip() if sector.text else \"No Sector available\"\n",
        "            return t_sec\n",
        "        else:\n",
        "            return f\"No sector found for {comp_name}\"\n",
        "    else:\n",
        "        return f\"ailed to get info. Error: {response.status_code}\""
      ],
      "metadata": {
        "id": "nJdxlT26HtsY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f_ind(comp_name,response):\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find all elements with the class (industry)\n",
        "        c_texts = soup.find_all('div', {'class': 'chip-text'})\n",
        "\n",
        "        if c_texts:\n",
        "            # Extract the text content of each 'chip-text'\n",
        "            descriptions = [chip_text.text.strip() for chip_text in c_texts]\n",
        "            i_str = ', '.join(descriptions)\n",
        "\n",
        "            return i_str\n",
        "        else:\n",
        "            return f\"No Info found for {comp_name}\"\n",
        "    else:\n",
        "        return f\"Failed to get info. Error: {response.status_code}\""
      ],
      "metadata": {
        "id": "ud5-1teDHuJq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def l_fund(comp_name,response):\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find all <a> elements with the specified class\n",
        "        a_elements = soup.find_all('a', {'class': 'component--field-formatter field-type-enum accent highlight-color-contrast-light ng-star-inserted'})\n",
        "\n",
        "        if a_elements and len(a_elements) >= 2:\n",
        "            # Extract and print the text content of the second <a> element\n",
        "            fund = a_elements[1].text.strip()\n",
        "            return fund\n",
        "        else:\n",
        "            return f\"No Funding found for {comp_name}\"\n",
        "    else:\n",
        "        return f\"Failed to get info. Error: {response.status_code}\""
      ],
      "metadata": {
        "id": "7J580182Huqe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f_compet(comp_name):\n",
        "    #since competitors information is on another page we are navigating to different api and extracting the information\n",
        "    url = f'https://www.crunchbase.com/organization/{comp_name.lower()}/org_similarity_overview'\n",
        "\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "    }\n",
        "    #time.sleep(2)\n",
        "    response = requests.get(url, headers=headers)\n",
        "    print(response.status_code)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Find all <a> elements with specific attributes\n",
        "        matching_a_elements = soup.find_all('div', {'class': 'reasons-container ng-star-inserted'})\n",
        "        com_name=soup.find('h1',{'class':'profile-name'})\n",
        "        if matching_a_elements and com_name:\n",
        "            # Extract and return the text content of all matching <a> elements in a list\n",
        "            results = [element.text.strip() for element in matching_a_elements]\n",
        "            compy_name=com_name.text.strip()\n",
        "            result=[]\n",
        "            #print(results)\n",
        "            for text in results:\n",
        "              # matches = re.findall(fr\"{company_name} and (\\w+)\", text)\n",
        "              pattern = re.compile(compy_name + r'\\s+and\\s+(\\w+)')\n",
        "              matches = pattern.findall(text)\n",
        "              result.extend(matches)\n",
        "            c_str = ', '.join(result)\n",
        "\n",
        "            return c_str\n",
        "        else:\n",
        "            return [f\"No Competitors found for {comp_name}\"]\n",
        "    else:\n",
        "        return [f\"Failed to get info. Error: {response.status_code}\"]"
      ],
      "metadata": {
        "id": "GRDM1TdjHvFu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def products(comp_name,response):\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        #print(soup)\n",
        "\n",
        "        p = soup.find('span', {'class': 'description has-overflow ng-star-inserted'})\n",
        "\n",
        "        if p:\n",
        "            # Check if text content is available\n",
        "            res = p.text.strip() if p.text else \"No info available\"\n",
        "            return res\n",
        "        else:\n",
        "            return f\"No Products/Services found for {comp_name}\"\n",
        "    else:\n",
        "        return f\"Failed to get info. Error: {response.status_code}\""
      ],
      "metadata": {
        "id": "dxLI3czkIAbu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(comp_name):\n",
        "  #Processing the Name of company before we pass it to the url\n",
        "  t_name=comp_name.lower().replace(' ', '-')\n",
        "  url = f'https://www.crunchbase.com/organization/{t_name}'\n",
        "\n",
        "  headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "  }\n",
        "\n",
        "  response = requests.get(url, headers=headers)\n",
        "  print(response.status_code)\n",
        "  #check the Response code\n",
        "  if response.status_code==200:\n",
        "    desc=comp_description(comp_name,response)\n",
        "    sec=fsector(comp_name,response)\n",
        "    ind=f_ind(comp_name,response)\n",
        "    fund=l_fund(comp_name,response)\n",
        "    compet=f_compet(t_name)\n",
        "    prod=products(comp_name,response)\n",
        "\n",
        "    return {\n",
        "            'Company Name' : comp_name,\n",
        "            'Company Description': desc,\n",
        "            'Sector': sec,\n",
        "            'Industry': ind,\n",
        "            'Funding': fund,\n",
        "            'Products/Services Description': prod,\n",
        "            'Competitors': compet\n",
        "        }\n",
        "  else:\n",
        "      print(f\"Failed to find information for {comp_name}\")\n",
        "      return None"
      ],
      "metadata": {
        "id": "6OrM7J79IA4P"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating Excel File for List of Companies\n",
        "def generate_excel_file(comp_names):\n",
        "    data = []\n",
        "    #Processing Each Company\n",
        "    for comp_name in comp_names:\n",
        "        company_info = test(comp_name)\n",
        "        time.sleep(2)\n",
        "        if company_info:\n",
        "            data.append(company_info)\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    excel_filename = 'out_file.xlsx'\n",
        "\n",
        "\n",
        "    df.to_excel(excel_filename, index=False)\n",
        "\n",
        "    print(f'Excel file \"{excel_filename}\" generated successfully.')\n",
        "\n",
        "\n",
        "\n",
        "company_names = ['Amazon','Microsoft','Facebook','Tesla']\n",
        "generate_excel_file(company_names)"
      ],
      "metadata": {
        "id": "UaXrsqecIBWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96cc72a9-a1f5-46c9-9c52-1c50b924a4e4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "200\n",
            "Excel file \"out_file.xlsx\" generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NYonmvbBIOiz"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KOMdA3NZIPWQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "II8w3fLDIPKX"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}